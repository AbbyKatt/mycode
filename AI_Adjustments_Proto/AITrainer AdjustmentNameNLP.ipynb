{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cross-encoder/ms-marco-TinyBERT-L-2-v2 were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-1): 2 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Embeddings model\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = \"cross-encoder/ms-marco-TinyBERT-L-2-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "embeddingsmodel = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Check if a GPU is available and move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embeddingsmodel.to(device)\n",
    "\n",
    "#Test functionaliy\n",
    "# # Tokenize the text field and create a tensor with the token IDs\n",
    "# text_field = \"This is an example text field.\"\n",
    "# inputs = tokenizer(text_field, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# # Obtain the embeddings\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "#     embeddings = outputs.last_hidden_state\n",
    "\n",
    "# # Calculate the average embedding\n",
    "# avg_embedding = embeddings.mean(dim=1).squeeze().cpu().numpy()\n",
    "# avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load SampleData.csv into a dataframe / turn labels into embeddings\n",
    "import pandas as pd\n",
    "df = pd.read_csv('SampleData.csv')\n",
    "\n",
    "#Get field AdjustmentName as list\n",
    "AdjustmentNames = df['AdjustmentName'].tolist()\n",
    "\n",
    "#Loop over every field and turn it into an embedding\n",
    "queryList=[]\n",
    "for AdjustmentName in AdjustmentNames:\n",
    "    text_field = AdjustmentName.replace('_', ' ').replace('-', ' ')\n",
    "    inputs = tokenizer(text_field, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = embeddingsmodel (**inputs)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "\n",
    "    #Turn embedding into a regular vector\n",
    "    avg_embedding = embeddings.mean(dim=1).squeeze().cpu().numpy()\n",
    "    queryList.append(avg_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdjustmentName_0</th>\n",
       "      <th>AdjustmentName_1</th>\n",
       "      <th>AdjustmentName_2</th>\n",
       "      <th>AdjustmentName_3</th>\n",
       "      <th>AdjustmentName_4</th>\n",
       "      <th>AdjustmentName_5</th>\n",
       "      <th>AdjustmentName_6</th>\n",
       "      <th>AdjustmentName_7</th>\n",
       "      <th>AdjustmentName_8</th>\n",
       "      <th>AdjustmentName_9</th>\n",
       "      <th>AdjustmentName_10</th>\n",
       "      <th>AdjustmentName_11</th>\n",
       "      <th>AdjustmentName_12</th>\n",
       "      <th>AdjustmentName_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AdjustmentName_0  AdjustmentName_1  AdjustmentName_2  AdjustmentName_3  \\\n",
       "0                     0                 0                 0                 1   \n",
       "1                     0                 1                 0                 0   \n",
       "2                     1                 0                 0                 0   \n",
       "3                     0                 0                 0                 0   \n",
       "4                     0                 0                 0                 0   \n",
       "...                 ...               ...               ...               ...   \n",
       "19995                 0                 0                 1                 0   \n",
       "19996                 0                 1                 0                 0   \n",
       "19997                 0                 0                 0                 0   \n",
       "19998                 0                 0                 0                 0   \n",
       "19999                 0                 1                 0                 0   \n",
       "\n",
       "       AdjustmentName_4  AdjustmentName_5  AdjustmentName_6  AdjustmentName_7  \\\n",
       "0                     0                 0                 0                 0   \n",
       "1                     0                 0                 0                 0   \n",
       "2                     0                 0                 0                 0   \n",
       "3                     0                 0                 0                 1   \n",
       "4                     0                 0                 0                 0   \n",
       "...                 ...               ...               ...               ...   \n",
       "19995                 0                 0                 0                 0   \n",
       "19996                 0                 0                 0                 0   \n",
       "19997                 0                 0                 0                 0   \n",
       "19998                 0                 0                 0                 0   \n",
       "19999                 0                 0                 0                 0   \n",
       "\n",
       "       AdjustmentName_8  AdjustmentName_9  AdjustmentName_10  \\\n",
       "0                     0                 0                  0   \n",
       "1                     0                 0                  0   \n",
       "2                     0                 0                  0   \n",
       "3                     0                 0                  0   \n",
       "4                     1                 0                  0   \n",
       "...                 ...               ...                ...   \n",
       "19995                 0                 0                  0   \n",
       "19996                 0                 0                  0   \n",
       "19997                 1                 0                  0   \n",
       "19998                 0                 0                  1   \n",
       "19999                 0                 0                  0   \n",
       "\n",
       "       AdjustmentName_11  AdjustmentName_12  AdjustmentName_13  \n",
       "0                      0                  0                  0  \n",
       "1                      0                  0                  0  \n",
       "2                      0                  0                  0  \n",
       "3                      0                  0                  0  \n",
       "4                      0                  0                  0  \n",
       "...                  ...                ...                ...  \n",
       "19995                  0                  0                  0  \n",
       "19996                  0                  0                  0  \n",
       "19997                  0                  0                  0  \n",
       "19998                  0                  0                  0  \n",
       "19999                  0                  0                  0  \n",
       "\n",
       "[20000 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Onehot encode the existing adjustment names\n",
    "#Get only the AdjustmentName column\n",
    "df2=df[['AdjustmentName']]\n",
    "\n",
    "#Get list of unique values produce mapping to numeric index\n",
    "uniqueValues=df2['AdjustmentName'].unique()\n",
    "uniqueValues.sort()\n",
    "\n",
    "#Create a dictionary of unique values\n",
    "uniqueValuesDict={}\n",
    "for i in range(len(uniqueValues)):\n",
    "    uniqueValuesDict[uniqueValues[i]]=i\n",
    "\n",
    "#Create an inverse dictionary of unique values\n",
    "uniqueValuesDictInverse={}\n",
    "for i in range(len(uniqueValues)):\n",
    "    uniqueValuesDictInverse[i]=uniqueValues[i]\n",
    "\n",
    "#Get AdjustmentName column as a list\n",
    "AdjustmentNames = df2['AdjustmentName'].tolist()\n",
    "\n",
    "#Replace AdjustmentName with numeric index\n",
    "for i in range(len(AdjustmentNames)):\n",
    "    AdjustmentNames[i]=uniqueValuesDict[AdjustmentNames[i]]\n",
    "\n",
    "#Make new dataframe from AdjustmentNames\n",
    "y = pd.DataFrame(AdjustmentNames, columns=['AdjustmentName'])\n",
    "\n",
    "#onehot encode the AdjustmentName column\n",
    "y = pd.get_dummies(y, columns=['AdjustmentName'])\n",
    "\n",
    "#Unpack lists in queryList and turn into a dataframe grid\n",
    "import numpy as np\n",
    "df_query = pd.DataFrame(np.array(queryList).reshape(len(queryList), 128))\n",
    "\n",
    "\n",
    "#df_query\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "16000\n",
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "#Break into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_query, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#Define model\n",
    "#Build model parameterized so we can do a grid-search on hyperparameters\n",
    "#model.fit(X_train, y_train, batch_size = 32, epochs = 80)\n",
    "\n",
    "def CreateModel(neurons=200, dropout=0.2,layers=3):\n",
    "\n",
    "    #------------------PARAMETERS------------------\n",
    "    num_classes=len(uniqueValuesDict)\n",
    "\n",
    "    #Simple feed-forward model. No U-nets or anything fancy\n",
    "    ann = tf.keras.models.Sequential()\n",
    "\n",
    "    #Variable number of layers\n",
    "    for i in range(layers):\n",
    "        ann.add(tf.keras.layers.Dense(units=neurons, activation='relu'))\n",
    "\n",
    "    #Final dropout layer at last fully connected layer before classification head\n",
    "    ann.add(tf.keras.layers.Dropout(dropout))\n",
    "    #ann.add(tf.keras.layers.Dense(units=num_classes, activation='sigmoid'))\n",
    "\n",
    "    # ann.add(tf.keras.layers.Flatten())\n",
    "    ann.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "    #Compile!\n",
    "    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  \n",
    "    \n",
    "    #ann.summary()\n",
    "    return ann\n",
    "\n",
    "model = KerasClassifier(build_fn=CreateModel, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'epochs': [1,2,4,8,16],\n",
    "    'neurons': [200, 300, 400],\n",
    "    \"dropout\":[0.05,0.1,0.2,0.4],\n",
    "    \"layers\":[1,2,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 1s 835us/step - loss: 0.0390 - accuracy: 0.9551\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 0s 822us/step - loss: 0.0014 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20839e64ca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid search for model parameters\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "#aModel=CreateModel()\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "# print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "#Best score: 1.000000 using {'dropout': 0.05, 'epochs': 1, 'layers': 1, 'neurons': 200}\n",
    "#Train model\n",
    "aModel=CreateModel(200,0.05,1)\n",
    "aModel.fit(X_train, y_train, batch_size = 32, epochs = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 546us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validate the model against the test set\n",
    "y_pred = aModel.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "#Get the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'German Retail Downturn'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a prediction\n",
    "# Tokenize the text field and create a tensor with the token IDs\n",
    "text_field = \"German retail sales fall unexpectedly in October\"\n",
    "inputs = tokenizer(text_field, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# Obtain the embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = embeddingsmodel(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "# Calculate the average embedding\n",
    "avg_embedding = embeddings.mean(dim=1).squeeze().cpu().numpy()\n",
    "avg_embedding\n",
    "\n",
    "import numpy as np\n",
    "df_query = pd.DataFrame(avg_embedding.reshape(1, 128))\n",
    "df_query\n",
    "\n",
    "#Make a prediction\n",
    "ret=aModel.predict(df_query)\n",
    "\n",
    "#Get the index of the highest value\n",
    "ret=np.argmax(ret)\n",
    "#ret\n",
    "\n",
    "# #Get the AdjustmentName from the index\n",
    "uniqueValuesDictInverse[ret]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>D</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>Q</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_weighted</th>\n",
       "      <th>entropy</th>\n",
       "      <th>has_esd</th>\n",
       "      <th>...</th>\n",
       "      <th>rf</th>\n",
       "      <th>sigma</th>\n",
       "      <th>spectral_norm</th>\n",
       "      <th>stable_rank</th>\n",
       "      <th>status</th>\n",
       "      <th>sv_max</th>\n",
       "      <th>warning</th>\n",
       "      <th>weak_rank_loss</th>\n",
       "      <th>xmax</th>\n",
       "      <th>xmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dense_2</td>\n",
       "      <td>0.057298</td>\n",
       "      <td>128</td>\n",
       "      <td>200</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>2.318774</td>\n",
       "      <td>2.878088</td>\n",
       "      <td>0.96355</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179462</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>14.398438</td>\n",
       "      <td>success</td>\n",
       "      <td>4.175781</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>17.437500</td>\n",
       "      <td>1.386719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>dense_3</td>\n",
       "      <td>0.144978</td>\n",
       "      <td>14</td>\n",
       "      <td>200</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>5.357099</td>\n",
       "      <td>4.279401</td>\n",
       "      <td>0.98135</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.540467</td>\n",
       "      <td>6.289062</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>success</td>\n",
       "      <td>2.507812</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>6.289062</td>\n",
       "      <td>3.626953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer_id     name         D    M    N          Q     alpha  alpha_weighted  \\\n",
       "0         0  dense_2  0.057298  128  200   1.562500  2.318774        2.878088   \n",
       "1         2  dense_3  0.144978   14  200  14.285714  5.357099        4.279401   \n",
       "\n",
       "   entropy  has_esd  ...  rf     sigma  spectral_norm  stable_rank   status  \\\n",
       "0  0.96355     True  ...   1  0.179462      17.437500    14.398438  success   \n",
       "1  0.98135     True  ...   1  1.540467       6.289062     8.500000  success   \n",
       "\n",
       "     sv_max  warning  weak_rank_loss       xmax      xmin  \n",
       "0  4.175781                        0  17.437500  1.386719  \n",
       "1  2.507812                        0   6.289062  3.626953  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weightwatcher\n",
    "import weightwatcher as ww\n",
    "watcher = ww.WeightWatcher(model=aModel)\n",
    "results = watcher.analyze(plot=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
