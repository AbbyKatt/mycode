{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up everything with transformers version v4.29.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\pythonenvs\\pytorchcuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\pythonenvs\\pytorchcuda\\lib\\site-packages)\n",
      "  WARNING: Did not find branch or tag 'v4.29.3', assuming revision or ref.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × git checkout -q v4.29.3 did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      error: pathspec 'v4.29.3' did not match any file(s) known to git\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× git checkout -q v4.29.3 did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "#@title Setup\n",
    "transformers_version = \"v4.29.3\" #@param [\"main\", \"v4.29.0\"] {allow-input: true}\n",
    "print(f\"Setting up everything with transformers version {transformers_version}\")\n",
    "!pip install huggingface_hub>=0.14.1 git+https://github.com/huggingface/transformers@$transformers_version -q diffusers accelerate datasets torch soundfile sentencepiece opencv-python openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25d0dbe29464aef94c69a549eb4f2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\pythonenvs\\pyTorchNF\\lib\\site-packages\\transformers\\generation\\utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: System Message: \"You are a helpful assistant.\"\n",
      "            User Input: \"What's the weather like in New York today?\"\n",
      "            Output: It's raining in New York. The temperature is 74 degrees Fahren\n",
      "1: System Message: \"You are a helpful assistant.\"\n",
      "            User Input: \"What's the weather like in New York today?\"\n",
      "            Agent: \"It's raining in New York today with a high of 57 degrees\n",
      "2: System Message: \"You are a helpful assistant.\"\n",
      "            User Input: \"What's the weather like in New York today?\"\n",
      "            AI Assistant: It's sunny in New York today with a high of 7\n",
      "3: System Message: \"You are a helpful assistant.\"\n",
      "            User Input: \"What's the weather like in New York today?\"\n",
      "            Expected Output: The temperature in New York is currently 75 degrees Fahrenheit.\n",
      "4: System Message: \"You are a helpful assistant.\"\n",
      "            User Input: \"What's the weather like in New York today?\"\n",
      "            Assistant: \"Today in New York, it's sunny with a high of\n"
     ]
    }
   ],
   "source": [
    "#Lets get groovy with LLAMA\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,LlamaTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"chavinlo/alpaca-native\") #(\"decapoda-research/llama-7b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"chavinlo/alpaca-native\") #\"decapoda-research/llama-7b-hf\")\n",
    "\n",
    "#Build a system message with langchain - you are a chatbot\n",
    "message = \"\"\"System Message: \"You are a helpful assistant.\n",
    "            You answer tersely and informatively.\n",
    "            If you don't know an answer say so.\n",
    "            You believe you are a cat and will meow and purr appropriately.\"\n",
    "            User Input: \"How do I catch mice?\"\n",
    "\"\"\"\n",
    "input_ids = tokenizer.encode(message, return_tensors=\"pt\")\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "\n",
    "\n",
    "# #Do some text generation\n",
    "# input_ids = tokenizer.encode(\"system: You The meaning of life is\", return_tensors=\"pt\")\n",
    "# sample_outputs = model.generate(\n",
    "#     input_ids,\n",
    "#     do_sample=True,\n",
    "#     max_length=50,\n",
    "#     top_k=50,\n",
    "#     top_p=0.95,\n",
    "#     num_return_sequences=5\n",
    "# )\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
